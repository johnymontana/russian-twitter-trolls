{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity extraction with polyglot\n",
    "\n",
    "Use the Polyglot Python library to enrich the tweet graph with extracted entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!polyglot download embeddings2.en ner2.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neo4j.v1 import GraphDatabase\n",
    "import json\n",
    "import pprint\n",
    "#from polyglot.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from neo4j.v1 import GraphDatabase\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\")\n",
    "\n",
    "\n",
    "with driver.session() as session:\n",
    "    results = session.run(\"MATCH (t:Tweet) RETURN t.text AS text, t.tweet_id AS tweet_id\")\n",
    "\n",
    "tweetObjArr = []\n",
    "\n",
    "for r in results:\n",
    "    tweetObj = {}\n",
    "    tweetObj['id'] = r['tweet_id']\n",
    "    tweetObj['text'] = r['text']\n",
    "    tweetObjArr.append(tweetObj)\n",
    "\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tweetObjArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entityArr = []\n",
    "\n",
    "\n",
    "for t in tweetObjArr:\n",
    "    try:\n",
    "        parsedTweet = {}\n",
    "        parsedTweet['id'] = t['id']\n",
    "        parsedTweet['text'] = t['text']\n",
    "        blob = Text(t['text'])\n",
    "        entities = blob.entities\n",
    "        parsedTweet['entities'] = []\n",
    "        for e in entities:\n",
    "            eobj = {}\n",
    "            eobj['tag'] = e.tag\n",
    "            eobj['entity'] = e\n",
    "            parsedTweet['entities'].append(eobj)\n",
    "        if len(parsedTweet['entities']) > 0:\n",
    "            entityArr.append(parsedTweet)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('parsed_tweets_scraped.json', 'w') as f:\n",
    "    json.dump(entityArr, f, ensure_ascii=False, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(entityArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entityArr[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'entities': [{'entity': I-PER(['Hillary', 'Clinton']), 'tag': 'I-PER'}],\n",
    " 'id': 773585101489922048,\n",
    " 'text': '@realDonaldTrump \"Hillary Clinton has zero record to run on - unless you call corruption positive..\" - @IngrahamAngle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"parsed_tweets_scraped.json\") as f:\n",
    "    parsed_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': [{'entity': ['Hillary'], 'tag': 'I-PER'}],\n",
      " 'id': '588771323289030657',\n",
      " 'text': 'Emails investigation made Hillary a dubious candidate #DemsWontPass'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(parsed_tweets[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run('CREATE CONSTRAINT ON (p:Person) ASSERT p.name IS UNIQUE;')\n",
    "    session.run('CREATE CONSTRAINT ON (l:Location) ASSERT l.name IS UNIQUE;')\n",
    "    session.run('CREATE CONSTRAINT ON (o:Organization) ASSERT o.name IS UNIQUE;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entity_import_query = '''\n",
    "WITH $parsedTweets AS parsedTweets\n",
    "UNWIND parsedTweets AS parsedTweet\n",
    "MATCH (t:Tweet) WHERE t.tweet_id = parsedTweet.id\n",
    "\n",
    "\n",
    "FOREACH(entity IN parsedTweet.entities |\n",
    "    // Person\n",
    "    FOREACH(_ IN CASE WHEN entity.tag = 'I-PER' THEN [1] ELSE [] END | \n",
    "        MERGE (p:Person {name: reduce(s = \"\", x IN entity.entity | s + x + \" \")}) //FIXME: trailing space\n",
    "        MERGE (p)<-[:CONTAINS_ENTITY]-(t)\n",
    "    )\n",
    "    \n",
    "    // Organization\n",
    "    FOREACH(_ IN CASE WHEN entity.tag = 'I-ORG' THEN [1] ELSE [] END | \n",
    "        MERGE (o:Organization {name: reduce(s = \"\", x IN entity.entity | s + x + \" \")}) //FIXME: trailing space\n",
    "        MERGE (o)<-[:CONTAINS_ENTITY]-(t)\n",
    "    )\n",
    "    \n",
    "    // Location\n",
    "    FOREACH(_ IN CASE WHEN entity.tag = 'I-LOC' THEN [1] ELSE [] END | \n",
    "        MERGE (l:Location {name: reduce(s = \"\", x IN entity.entity | s + x + \" \")}) // FIXME: trailing space\n",
    "        MERGE (l)<-[:CONTAINS_ENTITY]-(t)\n",
    "    )\n",
    ")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(entity_import_query, parsedTweets=parsed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
